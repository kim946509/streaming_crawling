# ---------- model í˜¸ì¶œ ----------
from streaming_site_list.youtube.models import YouTubeSongViewCount
# ---------- seleniumì—ì„œ importí•œ ëª©ë¡ ----------
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
# ---------- webdriverì—ì„œ importí•œ ëª©ë¡ ----------
from webdriver_manager.chrome import ChromeDriverManager
from contextlib import contextmanager
# ---------- í¬ë¡¤ë§ì„ ìœ„í•´ í•„ìš”í•œ ëª¨ë“ˆ ----------
from bs4 import BeautifulSoup
from datetime import datetime
import logging, time, re
import pandas as pd
from pathlib import Path

'''===================== logging ì„¤ì • ====================='''
logger = logging.getLogger(__name__)

SERVICE_NAMES = ["youtube", "youtube_music", "genie"]

'''===================== â¬‡ï¸ ê³ ê°ì‚¬/ì„œë¹„ìŠ¤ë³„ í´ë” ìƒì„± í•¨ìˆ˜ ====================='''
def get_csv_dir(company_name, service_name, base_dir='csv_folder'):
    dir_path = Path(base_dir) / company_name / service_name
    dir_path.mkdir(parents=True, exist_ok=True)
    return dir_path


'''===================== â¬‡ï¸ ê³ ê°ì‚¬ í•˜ìœ„ì— ì„œë¹„ìŠ¤ë³„ í´ë”ë¥¼ ëª¨ë‘ ìƒì„± í•¨ìˆ˜ ====================='''
def make_service_dirs_for_company(company_name, base_dir='csv_folder'):
    for service in SERVICE_NAMES:
        dir_path = Path(base_dir) / company_name / service
        dir_path.mkdir(parents=True, exist_ok=True)
        logger.info(f"âœ… {company_name} í•˜ìœ„ì— {service} í´ë” ìƒì„± ì™„ë£Œ")

'''===================== â¬‡ï¸ CSV íŒŒì¼ ì €ì¥ í•¨ìˆ˜ ====================='''
def save_each_to_csv(results, company_name):
    """
    ê° ê³¡ë³„ë¡œ service_nameì— ë”°ë¼ ê³ ê°ì‚¬/ì„œë¹„ìŠ¤ë³„ í´ë”ì— CSV ì €ì¥
    """
    make_service_dirs_for_company(company_name)
    filepaths = {}
    for song_id, data in results.items():
        service_name = data.get('service_name', 'youtube')  # ê¸°ë³¸ê°’ youtube
        CSV_DIR = Path('rhoonart') / company_name / service_name

        if data.get('view_count') is not None:
            try:
                data['view_count'] = int(data['view_count'])
            except (ValueError, TypeError):
                data['view_count'] = None
                logger.error(f"âŒ ì¡°íšŒìˆ˜ ë³€í™˜ ì‹¤íŒ¨: {data['view_count']}")

        song_name = data.get('song_name', 'unknown')
        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±° ë° ê³µë°±ì„ ì–¸ë”ë°”ë¡œ ë³€í™˜
        song_name_clean = re.sub(r'[\\/:*?"<>|]', '', song_name)
        song_name_clean = song_name_clean.replace(' ', '_')
        if not song_name_clean:
            song_name_clean = 'unknown'
        filename = f"{song_name_clean}.csv" # íŒŒì¼ëª…
        filepath = CSV_DIR / filename # íŒŒì¼ ì €ì¥ ê²½ë¡œ

        ''' â¬‡ï¸ DataFrame ìƒì„± (ì»¬ëŸ¼ ìˆœì„œ ì»¤ìŠ¤í…€ ê°€ëŠ¥)'''
        columns = ['song_name', 'view_count', 'youtube_url', 'upload_date', 'extracted_date']
        new_df = pd.DataFrame([{col: data.get(col) for col in columns}])

        # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì½ì–´ì„œ ëˆ„ì , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        if filepath.exists():
            try:
                old_df = pd.read_csv(filepath)
                combined_df = pd.concat([old_df, new_df], ignore_index=True)
            except Exception as e:
                logger.error(f"âŒ ê¸°ì¡´ CSV ì½ê¸° ì‹¤íŒ¨: {filepath} - {e}")
                combined_df = new_df
        else:
            combined_df = new_df

        # ì €ì¥
        combined_df.to_csv(filepath, index=False, encoding='utf-8-sig')
        logger.info(f"âœ… CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        filepaths[song_name] = str(filepath)
    return filepaths


'''===================== â¬‡ï¸ driver ì„¤ì • ====================='''
@contextmanager
def setup_driver():
    options = Options()
    # options.add_argument('--headless') # ë¸Œë¼ìš°ì € ì°½ ë¹„í™œì„±í™” : ì£¼ì„ì²˜ë¦¬í•˜ë©´ ë¸Œë¼ìš°ì € í™œì„±í™”
    options.add_argument('--no-sandbox') # ìƒŒë“œë°•ìŠ¤ ë¹„í™œì„±í™” (ë³´ì•ˆ ê¸°ëŠ¥ í•´ì œ)
    options.add_argument('--disable-dev-shm-usage')# ê³µìœ  ë©”ëª¨ë¦¬ ì‚¬ìš© ë¹„í™œì„±í™”
    options.add_argument('--disable-gpu') # GPU ë¹„í™œì„±í™”
    options.add_argument('--disable-blink-features=AutomationControlled') # ìë™í™” ë°©ì§€ ê¸°ëŠ¥ ë¹„í™œì„±í™”
    options.add_argument('--window-size=1920,1080')  # ë¸Œë¼ìš°ì € ì°½ í¬ê¸° ê³ ì •ìœ¼ë¡œ ì¼ê´€ëœ í¬ë¡¤ë§ í™˜ê²½ ì œê³µ
    options.add_argument('--start-maximized')  # ë¸Œë¼ìš°ì € ìµœëŒ€í™”
    options.add_argument('--incognito')  # ì‹œí¬ë¦¿ ëª¨ë“œ(ìºì‹œë‚˜ ì¿ í‚¤ì˜ ì˜í–¥ì„ ë°›ì§€ ì•ŠìŒ)
    options.add_argument('--disable-extensions')  # í™•ì¥ í”„ë¡œê·¸ë¨ ë¹„í™œì„±í™”(ì„±ëŠ¥ í–¥ìƒìš©)
    options.add_argument('--disable-popup-blocking')  # íŒì—… ì°¨ë‹¨ ë¹„í™œì„±í™”(í•„ìš”í•œ ê²½ìš° íŒì—… í—ˆìš© <- ì£¼ì„ ì²˜ë¦¬í•˜ë©´ í—ˆìš©)
    options.add_argument('--disable-notifications')  # ì•Œë¦¼ ë¹„í™œì„±í™”
    options.add_argument('--lang=ko_KR')  # ë¸Œë¼ìš°ì € í•œêµ­ì–´ ì„¤ì •
    options.add_argument('--log-level=3')  # ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì¶œë ¥ì„ ì¤„ì„
    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')  # User-Agent ì„¤ì •(ì¼ë°˜ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ë„ë¡)

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    logger.info("ğŸŸ¢ Chrome ë¸Œë¼ìš°ì € ì‹¤í–‰ ì™„ë£Œ")

    try:
        yield driver
    except Exception as e:
        logger.error(f"âŒ Chrome ë¸Œë¼ìš°ì € ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
        raise
    finally:
        driver.quit()
        logger.info("ğŸ”´ Chrome ë¸Œë¼ìš°ì € ì¢…ë£Œ")


'''===================== â¬‡ï¸ ì¡°íšŒìˆ˜ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ====================='''
def convert_view_count(view_count_text):
    """
    ì˜ˆ: "1.5ë§Œ íšŒ" -> 15000, "2.3ì²œ íšŒ" -> 2300, "1,234íšŒ" -> 1234, "9íšŒ" -> 9
    """
    if not view_count_text:
        return None
        
    # ì‰¼í‘œ, "ì¡°íšŒìˆ˜", "íšŒ" ì œê±°
    view_count_text = view_count_text.replace(',', '').replace('ì¡°íšŒìˆ˜', '').replace('íšŒ', '').strip()
    
    try:
        # "ë§Œ" ë‹¨ìœ„ ì²˜ë¦¬
        if 'ë§Œ' in view_count_text:
            number = float(view_count_text.replace('ë§Œ', ''))
            return int(number * 10000)
        # "ì²œ" ë‹¨ìœ„ ì²˜ë¦¬
        elif 'ì²œ' in view_count_text:
            number = float(view_count_text.replace('ì²œ', ''))
            return int(number * 1000)
        # ì¼ë°˜ ìˆ«ì ì²˜ë¦¬
        else:
            return int(view_count_text)
    except (ValueError, TypeError):
        logger.error(f"ì¡°íšŒìˆ˜ ë³€í™˜ ì‹¤íŒ¨: {view_count_text}")
        return None


'''===================== â¬‡ï¸ ìœ íŠœë¸Œ URLì—ì„œ song_id ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ ====================='''
def extract_song_id(youtube_url):
    """
    ìœ íŠœë¸Œ URLì—ì„œ song_id ì¶”ì¶œ
    """
    # ì¼ë°˜ì ì¸ ìœ íŠœë¸Œ URL íŒ¨í„´
    match = re.search(r"(?:v=|youtu\.be/)([A-Za-z0-9_-]{11})", youtube_url)
    if match:
        return match.group(1)
    return None


'''===================== â¬‡ï¸ í¬ë¡¤ë§ í•¨ìˆ˜ ====================='''
def YouTubeSongCrawler(urls):
    """
    ìœ íŠœë¸Œ URL ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ê° ë™ì˜ìƒì˜ ì •ë³´ë¥¼ í¬ë¡¤ë§
    Returns:
        dict: {
            song_id: {
                'song_name': str,  # ë™ì˜ìƒ ì œëª©
                'view_count': int,  # ì¡°íšŒìˆ˜ (ìˆ«ìí˜•)
                'youtube_url': str, # ìœ íŠœë¸Œ URL
                'upload_date': str, # ì—…ë¡œë“œ ë‚ ì§œ (YYYY.MM.DD í˜•ì‹)
                'extracted_date': str   # í¬ë¡¤ë§í•œ ë‚ ì§œì™€ ì‹œê°„ (YYYY.MM.DD í˜•ì‹)
            }
        }
    """
    results = {}
    url_id_map = {}

    # ê° urlì—ì„œ song_id ì¶”ì¶œ
    for url in urls:
        song_id = extract_song_id(url)
        if song_id:
            url_id_map[song_id] = url
        else:
            # ìœ íš¨í•˜ì§€ ì•Šì€ URL ì²˜ë¦¬
            results[url] = {
                'song_name': None,
                'view_count': None,
                'youtube_url': url,
                'upload_date': None,
                'extracted_date': datetime.now().strftime('%Y.%m.%d'),
                'error': 'ìœ íš¨í•˜ì§€ ì•Šì€ ìœ íŠœë¸Œ URL'
            }

    try:
        with setup_driver() as driver:
            wait = WebDriverWait(driver, 10)
            for song_id, url in url_id_map.items():
                try:
                    # í˜„ì¬ í¬ë¡¤ë§ ì‹œê°„ ê¸°ë¡
                    extracted_date = datetime.now().strftime('%Y.%m.%d')
                    youtube_url = url  # ì…ë ¥ë°›ì€ ì›ë³¸ URL ì‚¬ìš©

                    # í˜ì´ì§€ ë¡œë“œ
                    driver.get(youtube_url)

                    # ë™ì  ë¡œë”©ì„ ìœ„í•œ ëŒ€ê¸°
                    selectors = [
                        "h1.style-scope.ytd-watch-metadata",
                        "h1.style-scope.ytd-watch-metadata > yt-formatted-string",
                        "yt-formatted-string.style-scope.ytd-watch-metadata"
                    ]
                    found = False
                    for sel in selectors:
                        try:
                            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, sel)))
                            found = True
                            break
                        except:
                            continue
                    if not found:
                        # html ì €ì¥ ë“± ì¶”ê°€
                        raise Exception("ì œëª© selectorë¥¼ ì°¾ì§€ ëª»í•¨")
                    time.sleep(2)  # ì¶”ê°€ ëŒ€ê¸° ì‹œê°„

                    # HTML íŒŒì‹±
                    html = driver.page_source
                    soup = BeautifulSoup(html, 'html.parser')

                    # ë™ì˜ìƒ ì œëª© ì¶”ì¶œ (ì—¬ëŸ¬ selector ì‹œë„)
                    TITLE_SELECTORS = [
                            {'type': 'css', 'value': 'h1.style-scope.ytd-watch-metadata'},
                            {'type': 'css', 'value': 'h1.style-scope.ytd-watch-metadata > yt-formatted-string'},
                            {'type': 'css', 'value': 'yt-formatted-string.style-scope.ytd-watch-metadata'},
                            {'type': 'css', 'value': 'h1.title'},
                            {'type': 'css', 'value': 'h1.ytd-watch-metadata'},
                            {'type': 'css', 'value': 'h1#title'},
                        ]
                    
                    song_name = None
                    for selector in TITLE_SELECTORS:
                        result = None
                        if selector.get('type') == 'css':
                            result = soup.select_one(selector['value'])
                        elif selector.get('type') == 'tag_class':
                            result = soup.find(selector['tag'], class_=selector['class'])
                        elif selector.get('type') == 'tag_id':
                            result = soup.find(selector['tag'], id=selector['id'])
                        logger.debug(f"selector ì‹œë„: {selector} â†’ {'ì„±ê³µ' if result else 'ì‹¤íŒ¨'}")
                        if result:
                            song_name = result.text.strip()
                            logger.debug(f"selector {selector}ë¡œ ì¶”ì¶œëœ ì œëª©: {song_name}")
                            break
                    if not song_name:
                        song_name = "ì œëª© ì—†ìŒ"
                        logger.warning("ë™ì˜ìƒ ì œëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ëª¨ë“  selector ì‹¤íŒ¨.")
                    logger.info(f"ì œëª©: {song_name}")

                    # ì¡°íšŒìˆ˜ ì¶”ì¶œ
                    view_count_element = soup.find('span', class_='view-count')
                    view_count_text = view_count_element.text.strip() if view_count_element else None
                    view_count = convert_view_count(view_count_text)

                    # ì—…ë¡œë“œ ë‚ ì§œ ì¶”ì¶œ
                    info_text = soup.find('div', {'id': 'info-strings'})
                    upload_date = None
                    if info_text:
                        date_text = info_text.find('yt-formatted-string').text
                        # "YYYY. MM. DD." í˜•ì‹ì„ "YYYY-MM-DD" í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        date_match = re.search(r'(\d{4})\. (\d{1,2})\. (\d{1,2})\.', date_text)
                        if date_match:
                            year, month, day = date_match.groups()
                            upload_date = f"{year}.{month:0>2}.{day:0>2}"

                    # ê²°ê³¼ ì €ì¥
                    results[song_id] = {
                        'song_name': song_name,
                        'view_count': view_count,
                        'youtube_url': youtube_url,
                        'upload_date': upload_date,
                        'extracted_date': extracted_date
                    }

                    logger.info(f"âœ… í¬ë¡¤ë§ ì„±ê³µ - ì œëª©: {song_name}, ì¡°íšŒìˆ˜: {view_count}, ì—…ë¡œë“œì¼: {upload_date}")

                    # # ë””ë²„ê¹…ìš© HTML ì €ì¥
                    # with open(f"youtube_debug_{song_id}.html", "w", encoding="utf-8") as f:
                    #     f.write(driver.page_source)

                except Exception as e:
                    logger.error(f"âŒ {song_name} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}", exc_info=True)
                    results[song_id] = {
                        'song_name': None,
                        'view_count': None,
                        'youtube_url': url,
                        'upload_date': None,
                        'extracted_date': datetime.now().strftime('%Y.%m.%d'),
                    }
                    continue

        return results
    except Exception as e:
        logger.error(f"âŒ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return results


'''===================== â¬‡ï¸ ì—¬ëŸ¬ selectorë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•˜ì—¬ ì²« ë²ˆì§¸ë¡œ ì°¾ì€ element(ë˜ëŠ” text)ë¥¼ ë°˜í™˜ í•¨ìˆ˜ ====================='''
def find_with_selectors(soup, selectors, get_text=True):
    """
    ì—¬ëŸ¬ selectorë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•˜ì—¬ ì²« ë²ˆì§¸ë¡œ ì°¾ì€ element(ë˜ëŠ” text)ë¥¼ ë°˜í™˜
    """
    for selector in selectors:
        if selector.get('type') == 'css':
            el = soup.select_one(selector['value'])
        elif selector.get('type') == 'tag_class':
            el = soup.find(selector['tag'], class_=selector['class'])
        elif selector.get('type') == 'tag_id':
            el = soup.find(selector['tag'], id=selector['id'])
        else:
            continue
        if el:
            return el.text.strip() if get_text else el
    return None