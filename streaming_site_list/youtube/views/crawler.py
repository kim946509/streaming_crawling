# ---------- model í˜¸ì¶œ ----------
from streaming_site_list.youtube.models import YouTubeSongViewCount
# ---------- seleniumì—ì„œ importí•œ ëª©ë¡ ----------
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
# ---------- webdriverì—ì„œ importí•œ ëª©ë¡ ----------
from webdriver_manager.chrome import ChromeDriverManager
from contextlib import contextmanager
# ---------- í¬ë¡¤ë§ì„ ìœ„í•´ í•„ìš”í•œ ëª¨ë“ˆ ----------
from bs4 import BeautifulSoup
from datetime import datetime
import logging, time, re
import pandas as pd
from pathlib import Path

# ---------- CSV íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì • ----------
CSV_DIR = Path("song_crawling_result_csv/youtube")
CSV_DIR.mkdir(exist_ok=True)

# ---------- logging ì„¤ì • ----------
logger = logging.getLogger(__name__)


# ---------- â¬‡ï¸ driver ì„¤ì • ----------
@contextmanager
def setup_driver():
    options = Options()
    # options.add_argument('--headless') # ë¸Œë¼ìš°ì € ì°½ ë¹„í™œì„±í™” : ì£¼ì„ì²˜ë¦¬í•˜ë©´ ë¸Œë¼ìš°ì € í™œì„±í™”
    options.add_argument('--no-sandbox') # ìƒŒë“œë°•ìŠ¤ ë¹„í™œì„±í™” (ë³´ì•ˆ ê¸°ëŠ¥ í•´ì œ)
    options.add_argument('--disable-dev-shm-usage')# ê³µìœ  ë©”ëª¨ë¦¬ ì‚¬ìš© ë¹„í™œì„±í™”
    options.add_argument('--disable-gpu') # GPU ë¹„í™œì„±í™”
    options.add_argument('--disable-blink-features=AutomationControlled') # ìë™í™” ë°©ì§€ ê¸°ëŠ¥ ë¹„í™œì„±í™”
    options.add_argument('--window-size=1920,1080')  # ë¸Œë¼ìš°ì € ì°½ í¬ê¸° ê³ ì •ìœ¼ë¡œ ì¼ê´€ëœ í¬ë¡¤ë§ í™˜ê²½ ì œê³µ
    options.add_argument('--start-maximized')  # ë¸Œë¼ìš°ì € ìµœëŒ€í™”
    options.add_argument('--incognito')  # ì‹œí¬ë¦¿ ëª¨ë“œ(ìºì‹œë‚˜ ì¿ í‚¤ì˜ ì˜í–¥ì„ ë°›ì§€ ì•ŠìŒ)
    options.add_argument('--disable-extensions')  # í™•ì¥ í”„ë¡œê·¸ë¨ ë¹„í™œì„±í™”(ì„±ëŠ¥ í–¥ìƒìš©)
    options.add_argument('--disable-popup-blocking')  # íŒì—… ì°¨ë‹¨ ë¹„í™œì„±í™”(í•„ìš”í•œ ê²½ìš° íŒì—… í—ˆìš© <- ì£¼ì„ ì²˜ë¦¬í•˜ë©´ í—ˆìš©)
    options.add_argument('--disable-notifications')  # ì•Œë¦¼ ë¹„í™œì„±í™”
    options.add_argument('--lang=ko_KR')  # ë¸Œë¼ìš°ì € í•œêµ­ì–´ ì„¤ì •
    options.add_argument('--log-level=3')  # ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì¶œë ¥ì„ ì¤„ì„
    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')  # User-Agent ì„¤ì •(ì¼ë°˜ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ë„ë¡)

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    logger.info("ğŸŸ¢ Chrome ë¸Œë¼ìš°ì € ì‹¤í–‰ ì™„ë£Œ")

    try:
        yield driver
    except Exception as e:
        logger.error(f"âŒ Chrome ë¸Œë¼ìš°ì € ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
        raise
    finally:
        driver.quit()
        logger.info("ğŸ”´ Chrome ë¸Œë¼ìš°ì € ì¢…ë£Œ")

# ---------- â¬‡ï¸ CSV íŒŒì¼ ì €ì¥ í•¨ìˆ˜ ----------
def save_each_to_csv(results):
    """
    ê° ê³¡ë³„ë¡œ CSV íŒŒì¼ì„ ì €ì¥
    """
    filepaths = {}
    for song_id, data in results.items():
        if data.get('view_count') is not None:
            try:
                data['view_count'] = int(data['view_count'])
            except (ValueError, TypeError):
                data['view_count'] = None
                logger.error(f"âŒ ì¡°íšŒìˆ˜ ë³€í™˜ ì‹¤íŒ¨: {data['view_count']}")

        song_name = data.get('song_name', 'unknown')
        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±° ë° ê³µë°±ì„ ì–¸ë”ë°”ë¡œ ë³€í™˜
        song_name_clean = re.sub(r'[\\/:*?"<>|]', '', song_name)
        song_name_clean = song_name_clean.replace(' ', '_')
        if not song_name_clean:
            song_name_clean = 'unknown'
        filename = f"{song_name_clean}_{datetime.now().strftime('%y%m%d_%H%M%S')}.csv"
        filepath = CSV_DIR / filename

        # DataFrame ìƒì„± (í•œ ê³¡ë§Œ)
        df = pd.DataFrame([data])
        df.index.name = 'song_id'
        df.reset_index(inplace=True)
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        logger.info(f"âœ… CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        filepaths[song_id] = str(filepath)
    return filepaths

# ---------- â¬‡ï¸ DB ì €ì¥ í•¨ìˆ˜ ----------
def save_to_db(results):
    """
    í¬ë¡¤ë§ ê²°ê³¼ë¥¼ DBì— ì €ì¥
    """
    for song_id, data in results.items():
        try:
            YouTubeSongViewCount.objects.create(
                song_id=song_id,
                song_name=data['song_name'],
                view_count=data['view_count'],
                youtube_url=f"https://www.youtube.com/watch?v={song_id}",
                upload_date=data['upload_date'],
                extracted_date=data['extracted_date']
            )
        except Exception as e:
            logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨ (song_id: {song_id}): {e}")


# ---------- â¬‡ï¸ ì¡°íšŒìˆ˜ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ----------
def convert_view_count(view_count_text):
    """
    ì˜ˆ: "1.5ë§Œ íšŒ" -> 15000, "2.3ì²œ íšŒ" -> 2300, "1,234íšŒ" -> 1234, "9íšŒ" -> 9
    """
    if not view_count_text:
        return None
        
    # ì‰¼í‘œ, "ì¡°íšŒìˆ˜", "íšŒ" ì œê±°
    view_count_text = view_count_text.replace(',', '').replace('ì¡°íšŒìˆ˜', '').replace('íšŒ', '').strip()
    
    try:
        # "ë§Œ" ë‹¨ìœ„ ì²˜ë¦¬
        if 'ë§Œ' in view_count_text:
            number = float(view_count_text.replace('ë§Œ', ''))
            return int(number * 10000)
        # "ì²œ" ë‹¨ìœ„ ì²˜ë¦¬
        elif 'ì²œ' in view_count_text:
            number = float(view_count_text.replace('ì²œ', ''))
            return int(number * 1000)
        # ì¼ë°˜ ìˆ«ì ì²˜ë¦¬
        else:
            return int(view_count_text)
    except (ValueError, TypeError):
        logger.error(f"ì¡°íšŒìˆ˜ ë³€í™˜ ì‹¤íŒ¨: {view_count_text}")
        return None


# ---------- â¬‡ï¸ ìœ íŠœë¸Œ URLì—ì„œ song_id ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ ----------
def extract_song_id(youtube_url):
    """
    ìœ íŠœë¸Œ URLì—ì„œ song_id ì¶”ì¶œ
    """
    # ì¼ë°˜ì ì¸ ìœ íŠœë¸Œ URL íŒ¨í„´
    match = re.search(r"(?:v=|youtu\.be/)([A-Za-z0-9_-]{11})", youtube_url)
    if match:
        return match.group(1)
    return None


def find_with_selectors(soup, selectors, get_text=True):
    """
    ì—¬ëŸ¬ selectorë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•˜ì—¬ ì²« ë²ˆì§¸ë¡œ ì°¾ì€ element(ë˜ëŠ” text)ë¥¼ ë°˜í™˜
    """
    for selector in selectors:
        if selector.get('type') == 'css':
            el = soup.select_one(selector['value'])
        elif selector.get('type') == 'tag_class':
            el = soup.find(selector['tag'], class_=selector['class'])
        elif selector.get('type') == 'tag_id':
            el = soup.find(selector['tag'], id=selector['id'])
        else:
            continue
        if el:
            return el.text.strip() if get_text else el
    return None


# ---------- â¬‡ï¸ í¬ë¡¤ë§ í•¨ìˆ˜ ----------
def YouTubeSongCrawler(urls):
    """
    ìœ íŠœë¸Œ URL ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ê° ë™ì˜ìƒì˜ ì •ë³´ë¥¼ í¬ë¡¤ë§
    Returns:
        dict: {
            song_id: {
                'song_name': str,  # ë™ì˜ìƒ ì œëª©
                'view_count': int,  # ì¡°íšŒìˆ˜ (ìˆ«ìí˜•)
                'youtube_url': str, # ìœ íŠœë¸Œ URL
                'upload_date': str, # ì—…ë¡œë“œ ë‚ ì§œ (YYYY.MM.DD í˜•ì‹)
                'extracted_date': str   # í¬ë¡¤ë§í•œ ë‚ ì§œì™€ ì‹œê°„ (YYYY.MM.DD í˜•ì‹)
            }
        }
    """
    results = {}
    url_id_map = {}

    # ê° urlì—ì„œ song_id ì¶”ì¶œ
    for url in urls:
        song_id = extract_song_id(url)
        if song_id:
            url_id_map[song_id] = url
        else:
            # ìœ íš¨í•˜ì§€ ì•Šì€ URL ì²˜ë¦¬
            results[url] = {
                'song_name': None,
                'view_count': None,
                'youtube_url': url,
                'upload_date': None,
                'extracted_date': datetime.now().strftime('%Y.%m.%d'),
                'error': 'ìœ íš¨í•˜ì§€ ì•Šì€ ìœ íŠœë¸Œ URL'
            }

    try:
        with setup_driver() as driver:
            wait = WebDriverWait(driver, 10)
            for song_id, url in url_id_map.items():
                try:
                    # í˜„ì¬ í¬ë¡¤ë§ ì‹œê°„ ê¸°ë¡
                    extracted_date = datetime.now().strftime('%Y.%m.%d')
                    youtube_url = url  # ì…ë ¥ë°›ì€ ì›ë³¸ URL ì‚¬ìš©

                    # í˜ì´ì§€ ë¡œë“œ
                    driver.get(youtube_url)

                    # ë™ì  ë¡œë”©ì„ ìœ„í•œ ëŒ€ê¸°
                    wait.until(EC.presence_of_element_located((By.TAG_NAME, "ytd-watch-metadata")))
                    time.sleep(2)  # ì¶”ê°€ ëŒ€ê¸° ì‹œê°„

                    # HTML íŒŒì‹±
                    html = driver.page_source
                    soup = BeautifulSoup(html, 'html.parser')

                    # ë™ì˜ìƒ ì œëª© ì¶”ì¶œ (ì—¬ëŸ¬ selector ì‹œë„)
                    title_selectors = [
                        {'type': 'css', 'value': 'h1.title'},
                        {'type': 'css', 'value': 'h1.ytd-watch-metadata'},
                        {'type': 'tag_class', 'tag': 'h1', 'class': 'style-scope ytd-watch-metadata'},
                    ]
                    song_name = find_with_selectors(soup, title_selectors)

                    # ì¡°íšŒìˆ˜ ì¶”ì¶œ (ì—¬ëŸ¬ selector ì‹œë„)
                    view_count_selectors = [
                        {'type': 'css', 'value': 'span.view-count'},
                        {'type': 'css', 'value': 'span.ytd-video-view-count-renderer'},
                        {'type': 'tag_class', 'tag': 'span', 'class': 'view-count'},
                    ]
                    view_count_text = find_with_selectors(soup, view_count_selectors)
                    view_count = convert_view_count(view_count_text)

                    # ì—…ë¡œë“œ ë‚ ì§œ ì¶”ì¶œ (ì—¬ëŸ¬ selector ì‹œë„)
                    upload_date_selectors = [
                        {'type': 'css', 'value': 'div#info-strings yt-formatted-string'},
                        {'type': 'css', 'value': 'div#date yt-formatted-string'},
                        {'type': 'tag_id', 'tag': 'div', 'id': 'info-strings'},
                    ]
                    upload_date = None
                    date_text = find_with_selectors(soup, upload_date_selectors)
                    if date_text:
                        date_match = re.search(r'(\d{4})\. ?(\d{1,2})\. ?(\d{1,2})\.', date_text)
                        if date_match:
                            year, month, day = date_match.groups()
                            upload_date = f"{year}.{month:0>2}.{day:0>2}"

                    # ê²°ê³¼ ì €ì¥
                    results[song_id] = {
                        'song_name': song_name,
                        'view_count': view_count,
                        'youtube_url': youtube_url,
                        'upload_date': upload_date,
                        'extracted_date': extracted_date
                    }

                    logger.info(f"âœ… {song_id} í¬ë¡¤ë§ ì„±ê³µ - ì œëª©: {song_name}, ì¡°íšŒìˆ˜: {view_count}, ì—…ë¡œë“œì¼: {upload_date}")

                except Exception as e:
                    logger.error(f"âŒ {song_id} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}", exc_info=True)
                    results[song_id] = {
                        'song_name': None,
                        'view_count': None,
                        'youtube_url': url,
                        'upload_date': None,
                        'extracted_date': datetime.now().strftime('%Y.%m.%d'),
                    }
                    continue

        # í¬ë¡¤ë§ ê²°ê³¼ë¥¼ DBì™€ CSV íŒŒì¼ì— ì €ì¥
        save_to_db(results)
        save_each_to_csv(results)
        logger.info(f"âœ… í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ ì™„ë£Œ - CSV: {save_each_to_csv(results)}")

        return results
    except Exception as e:
        logger.error(f"âŒ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return results
